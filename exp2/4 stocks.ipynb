{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting\n",
    "**P.S. The final result goes to the end**\n",
    "### get the stock list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list_url = 'http://quote.eastmoney.com/stocklist.html'\n",
    "def get_html(url):\n",
    "    try:\n",
    "        useragent = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0'} #模拟浏览器\n",
    "        rsp = rq.get(url, timeout=10, headers=useragent)\n",
    "        rsp.raise_for_status() #根据状态码抛出HTTPError异常\n",
    "        rsp.encoding = rsp.apparent_encoding #使得解码正确\n",
    "        return rsp.text\n",
    "    except:\n",
    "        return \"Exception with staus code:\"+rsp.staus_code\n",
    "stock_list_rsp = get_html(stock_list_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下图为网页源代码\n",
    "\n",
    "<img src='pics\\stockls_src.png' style='float: left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`<a name=''></a>`后面的`<ul>`就是要求的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(stock_list_rsp, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = soup.find('div', attrs={'id':'quotesearch'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick the sh stock as an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n",
      " <li>\n",
      "  <a href=\"http://quote.eastmoney.com/sh201000.html\" target=\"_blank\">\n",
      "   R003(201000)\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"http://quote.eastmoney.com/sh201001.html\" target=\"_blank\">\n",
      "   R007(201001)\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"http://quote.eastmoney.com/sh201002.html\" target=\"_blank\">\n",
      "   R014(201002)\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"http://quote.eastmoney.com/sh201003.html\" target=\"_blank\">\n",
      "   R028(201003)\n",
      "  </a>\n",
      " </li>\n",
      " <li>\n",
      "  <a href=\"http://quote.eastmoney.com/sh201004.html\" target=\"_bla\n"
     ]
    }
   ],
   "source": [
    "uls = tmp.find_all('ul')\n",
    "sh_stocks = uls[0]\n",
    "print(sh_stocks.prettify()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what we want on this page\n",
    "the detail page of a certain stock follows the pattern of  \n",
    "`https://gupiao.baidu.com/stock/sh600709.html`  \n",
    "where the resource locator ends with the stock id  \n",
    "so the stock id mapped from the stock name is what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_stock_maps = {a.string:a.attrs['href'][:-5].split(r'/')[-1] for a in sh_stocks.find_all('a')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a.string`是股票名字  \n",
    "`a.attrs['href']`可以拿到url，再进一步截取出来id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtaining details from gupiao.baidu.com\n",
    "still i'm taking the first one to make an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_stock_id = list(sh_stock_maps.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gupiao.baidu.com/stock/sh201000.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_detail_url = r'https://gupiao.baidu.com/stock/{}.html'.format(one_stock_id)\n",
    "stock_detail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_page_rsp = get_html(stock_detail_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先分析一下页面代码，如下图就是所有需要的信息\n",
    "\n",
    "<img src='pics\\panel.png' style='float: left;'>\n",
    "右图中的两个line对应了上面的两行\n",
    "<img src='pics\\stockdetail.png' style='float: left;'>\n",
    "<img src='pics\\2line.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'prettify'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e38cb9ffbbaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'price s-up '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'prettify'"
     ]
    }
   ],
   "source": [
    "soup = bs(detail_page_rsp, 'html.parser')\n",
    "info = []\n",
    "title = soup.find('div', class_='price s-up ')\n",
    "print(title.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而实际上定位不到这个标签，所以就看了下上下文  \n",
    "发现现在用做实验的页面是没有上面的很多信息的\n",
    "\n",
    "<img src='pics\\error.png' style='float: left;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"stock-bets\">\n",
      " <h1>\n",
      "  <a class=\"bets-name\" href=\"/stock/sh201000.html\">\n",
      "   R003 (\n",
      "   <span>\n",
      "    201000\n",
      "   </span>\n",
      "   )\n",
      "  </a>\n",
      "  <span class=\"state f-up\">\n",
      "   已休市 2018-03-30  15:01:30\n",
      "  </span>\n",
      " </h1>\n",
      " <div class=\"price s-stop \">\n",
      "  <strong class=\"_close\">\n",
      "   2.00\n",
      "  </strong>\n",
      "  <span>\n",
      "   --\n",
      "  </span>\n",
      "  <span>\n",
      "   0.00%\n",
      "  </span>\n",
      " </div>\n",
      " <div class=\"bets-content\">\n",
      "  <div class=\"clear\">\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_bets = soup.find('div', class_='stock-bets')\n",
    "print(stock_bets.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找了一个折中办法：只用一个`class`定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"price s-stop \">\n",
       "<strong class=\"_close\">2.00</strong>\n",
       "<span>--</span>\n",
       "<span>0.00%</span>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gupiao.baidu.com/stock/sh603903.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_detail_url = r'https://gupiao.baidu.com/stock/{}.html'.format(list(sh_stock_maps.values())[-100])\n",
    "stock_detail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(get_html(stock_detail_url), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this should be normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"price s-up \">\n",
      " <strong class=\"_close\">\n",
      "  33.88\n",
      " </strong>\n",
      " <span>\n",
      "  +0.85\n",
      " </span>\n",
      " <span>\n",
      "  +2.57%\n",
      " </span>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title = soup.find('div', class_='price s-up ')\n",
    "print(title.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <strong class=\"_close\">33.88</strong>,\n",
       " '\\n',\n",
       " <span>+0.85</span>,\n",
       " '\\n',\n",
       " <span>+2.57%</span>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in title.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33.88', '+0.85', '+2.57%']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.string for x in title.children if x!='\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 然后解析2line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今开', '33.10'],\n",
       " ['成交量', '3.44万手'],\n",
       " ['最高', '34.99'],\n",
       " ['涨停', '36.33'],\n",
       " ['内盘', '1.66万手'],\n",
       " ['成交额', '1.17亿'],\n",
       " ['委比', '75.19%'],\n",
       " ['流通市值', '25.00亿'],\n",
       " [None, '56.29'],\n",
       " ['每股收益', '0.60'],\n",
       " ['总股本', '1.03亿']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line1 = soup.find('div', class_='line1')\n",
    "dls = line1.find_all('dl')\n",
    "line1.children\n",
    "[[c.string for c in dl.children] for dl in dls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None很麻烦要想办法去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dt class=\"mt-1\">市盈率<sup>MRQ</sup></dt>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = dls[8].children # the eighth dl\n",
    "tmp = [x for x in tmp] # unwrap cuz tmp is an iterator\n",
    "tmp = tmp[0] # pick the first who produces that 'None'\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['市盈率', <sup>MRQ</sup>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由于出现嵌套，用string对第9个dl拿不到文本，所以换一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今开', '33.10'],\n",
       " ['成交量', '3.44万手'],\n",
       " ['最高', '34.99'],\n",
       " ['涨停', '36.33'],\n",
       " ['内盘', '1.66万手'],\n",
       " ['成交额', '1.17亿'],\n",
       " ['委比', '75.19%'],\n",
       " ['流通市值', '25.00亿'],\n",
       " ['市盈率', '56.29'],\n",
       " ['每股收益', '0.60'],\n",
       " ['总股本', '1.03亿']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line1 = soup.find('div', class_='line1')\n",
    "dls = line1.find_all('dl')\n",
    "[[c.contents[0] for c in dl.children] for dl in dls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1_infos = [[c.contents[0] for c in dl.children] for dl in dls]\n",
    "titles,values = [x for x in zip(*line1_infos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('今开', '成交量', '最高', '涨停', '内盘', '成交额', '委比', '流通市值', '市盈率', '每股收益', '总股本')\n",
      "('33.10', '3.44万手', '34.99', '36.33', '1.66万手', '1.17亿', '75.19%', '25.00亿', '56.29', '0.60', '1.03亿')\n"
     ]
    }
   ],
   "source": [
    "print(titles)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试一下line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-54b31481acc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mline2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'line2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-54b31481acc4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mline2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'line2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-54b31481acc4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mline2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'line2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    735\u001b[0m             raise AttributeError(\n\u001b[0;32m    736\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[1;32m--> 737\u001b[1;33m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "line2 = soup.find('div', class_='line2')\n",
    "dls = line2.find_all('dl')\n",
    "[[c.contents[0] for c in dl.children] for dl in dls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面出错的原因是有个NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag, bs4.element.NavigableString],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag],\n",
       " [bs4.element.Tag, bs4.element.Tag]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line2 = soup.find('div', class_='line2')\n",
    "dls = line2.find_all('dl')\n",
    "[[type(c) for c in dl.children] for dl in dls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为了和line1写法兼容找了这么个折中办法\n",
    "顺便`strip()`把没用的空格换行去了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['昨收', '33.03'],\n",
       " ['换手率', '4.67%'],\n",
       " ['最低', '33.10'],\n",
       " ['跌停', '29.73'],\n",
       " ['外盘', '1.79万手'],\n",
       " ['振幅', '5.72%'],\n",
       " ['量比', '--'],\n",
       " ['总市值', '35.01亿'],\n",
       " ['市净率', '4.88'],\n",
       " ['每股净资产', '6.94'],\n",
       " ['流通股本', '7379.97万']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line2 = soup.find('div', class_='line2')\n",
    "dls = line2.find_all('dl')\n",
    "[[c.contents[0].strip('\\n ') for c in dl.children if isinstance(c, type(line2))] for dl in dls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final codes\n",
    "**P.S. jupyter上多线程可能有点问题，运行的话还是在pycharm跑stock.py，代码是一样的**\n",
    "### featuring\n",
    "1. multithreading using `threading`\n",
    "2. IO using `pandas`: writing csv (convenient for appending data)\n",
    "3. tradeoff between memory and IO overhead :  \n",
    "take the approach of periodical IO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convenient function for obtaining text of a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    try:\n",
    "        useragent = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0'}  # 模拟浏览器\n",
    "        rsp = rq.get(url, headers=useragent)\n",
    "        rsp.raise_for_status()  # 根据状态码抛出HTTPError异常\n",
    "        rsp.encoding = rsp.apparent_encoding  # 使得解码正确\n",
    "        print('succeed in requesting url {}'.format(url))\n",
    "        return rsp.text\n",
    "    except Exception as e:\n",
    "        print(\"Error occurs when requesting url {}\\n\" + url + repr(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the function for extracting stock name with its id from the `eastmoney` website\n",
    "there are exactly two elements in `mappings`: the shanghai stock and shenzhen stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mappings():\n",
    "    stock_list_url = 'http://quote.eastmoney.com/stocklist.html'\n",
    "    stock_list_rsp = get_html(stock_list_url)\n",
    "    soup = bs(stock_list_rsp, 'html.parser')\n",
    "    tmp = soup.find('div', attrs={'id': 'quotesearch'})\n",
    "    uls = tmp.find_all('ul')\n",
    "\n",
    "    mappings = []  # a list of 2, each dict\n",
    "    for ul in uls:\n",
    "        mappings.append({a.string: a.attrs['href'][:-5].split(r'/')[-1] for a in ul.find_all('a')})\n",
    "\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the function for extracting details for the given stock\n",
    "the stock info is given in the form of tupe, i.e. (name,id)  \n",
    "two aforementioned steps are merged into this function:\n",
    "1. extracting the heading \n",
    "2. extracting two line details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_stock_detail(stock):\n",
    "    name, stock_id = stock\n",
    "\n",
    "    stock_detail_url = r'https://gupiao.baidu.com/stock/{}.html'.format(stock_id)\n",
    "    detail_page_rsp = get_html(stock_detail_url)\n",
    "    if detail_page_rsp is None:\n",
    "        print('fail to load {}'.format(stock_detail_url))\n",
    "    soup = bs(detail_page_rsp, 'html.parser')\n",
    "\n",
    "    head = soup.find('div', class_='price')\n",
    "    if head is None:\n",
    "        print('{} with id={} has no information on gupiao.baidu.com'.format(name, stock_id))\n",
    "        return list(stock) + [None] * 25\n",
    "\n",
    "    head_values = list(stock) + [x.string for x in head.children if x != '\\n']\n",
    "\n",
    "    lines = ('line1', 'line2')\n",
    "    for line in lines:\n",
    "        linetag = soup.find('div', class_=line)\n",
    "        if linetag is None:\n",
    "            head_values += [None] * 22\n",
    "            break\n",
    "        dls = linetag.find_all('dl')\n",
    "        contents = [[c.contents[0] for c in dl.children if isinstance(c, type(linetag))] for dl in dls]\n",
    "        line_titles, line_values = [x for x in zip(*contents)]\n",
    "\n",
    "        head_values.extend(line_values)\n",
    "\n",
    "    return head_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the function for multithreading\n",
    "the crawling of the stocks is organized as such:\n",
    "1. take a small batch of stock_info\n",
    "2. concurrently fetching data of this batch using multithreading\n",
    "3. feed this batch of data to csv file\n",
    "4. loop   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "def threading_data(data=None, fn=None, thread_count=None, **kwargs):\n",
    "\n",
    "    def apply_fn(results, i, data, kwargs):\n",
    "        results[i] = fn(data, **kwargs)\n",
    "\n",
    "    if thread_count is None:\n",
    "        results = [None] * len(data)\n",
    "        threads = []\n",
    "        # for i in range(len(data)):\n",
    "        #     t = threading.Thread(name='threading_and_return', target=apply_fn, args=(results, i, data[i], kwargs))\n",
    "        for i, d in enumerate(data):\n",
    "            t = threading.Thread(name='threading_and_return', target=apply_fn, args=(results, i, d, kwargs))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "    else:\n",
    "        divs = np.linspace(0, len(data), thread_count + 1)\n",
    "        divs = np.round(divs).astype(int)\n",
    "        results = [None] * thread_count\n",
    "        threads = []\n",
    "        for i in range(thread_count):\n",
    "            t = threading.Thread(name='threading_and_return', target=apply_fn, args=(results, i, data[divs[i]:divs[i + 1]], kwargs))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    if thread_count is None:\n",
    "        try:\n",
    "            return np.asarray(results)\n",
    "        except Exception:\n",
    "            return results\n",
    "    else:\n",
    "        return np.concatenate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    n_parallel = 20\n",
    "    save_path = 'test.csv'\n",
    "    mappings = extract_mappings()\n",
    "\n",
    "    titles = ['名称', 'id', '今收', '增幅', '增比', '今开', '成交量', '最高', '涨停', '内盘', '成交额', '委比', '流通市值', '市盈率', '每股收益', '总股本',\n",
    "              '昨收', '换手率', '最低', '跌停', '外盘', '振幅', '量比', '总市值', '市净率', '每股净资产', '流通股本']\n",
    "\n",
    "    for mapping in mappings:  # sh & sz\n",
    "\n",
    "        stocks = list(mapping.items())\n",
    "        rounds = (len(stocks) - 1) // n_parallel + 1\n",
    "        gen = (stocks[i * n_parallel:min(len(stocks), (i + 1) * n_parallel)] for i in range(rounds))\n",
    "\n",
    "        # pool = ProcessPool(n_parallel)\n",
    "\n",
    "        start = True\n",
    "        for batch in gen:\n",
    "\n",
    "            med_results = threading_data(batch, one_stock_detail)\n",
    "\n",
    "            if start:\n",
    "                df = pd.DataFrame(med_results, columns=titles)\n",
    "                df.to_csv(save_path, index=False)\n",
    "                start = False\n",
    "            else:  # https://gupiao.baidu.com/stock/sh500009.html\n",
    "                df = pd.DataFrame(med_results)\n",
    "                df.to_csv('test.csv', mode='a', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
